AI_PROVIDER_TYPE: openai-instruct
BOT_USERNAME: pepeleli
MAX_CONCURRENT_AI_REQUESTS: 8
OPENAI_INSTRUCT_PROVIDER_BASE_URI: https://api.openai.com/v1
OPENAI_INSTRUCT_RESPONSE_MODEL: gpt-3.5-turbo-instruct
OPENAI_PROVIDER_BASE_URI: https://api.openai.com/v1
OPENAI_RESPONSE_MODEL: gpt-3.5-turbo-instruct
OPENAI_MAX_CONTEXT_LEN: 4090
OPENAI_MODERATION_THRESHOLD: 0
PERSIST_HISTORY: false
STOP_SEQUENCES: >
  ["<messageID="]
VLLM_AI_PROVIDER_HOST: nc1vc7xjib0jta-8000.proxy.runpod.net
VLLM_AI_PROVIDER_PORT: 443
VLLM_MAX_CONTEXT_LEN: 4090
VLLM_RESPONSE_MODEL: TheBloke/Nous-Hermes-Llama2-70B-AWQ
RATE_LIMITS: >
  {
      "tier_1": {"messages": 8, "interval": 60},
      "tier_2": {"messages": 25, "interval": 300},
      "tier_3": {"messages": 50, "interval": 3600},
      "tier_4": {"messages": 150, "interval": 86400}
  }
ANNOUNCE_CHANNELS: >
  [1157565053143351318]
MONITOR_CHANNELS: >
  [
    1104075734189887610, 
    1157565053143351318, 
    805183342185938977,
    946937513409404958, 
    953372263397351474, 
    957070831744339981, 
    1031992547981139988,
    1104075734189887610, 
    1141605158309068932, 
    987919126452371516, 
    870146840182530118,
    1141155800253993070, 
    1162593088099852359, 
    1162593108240904202, 
    1162644290246291476,
    1162644311041650709, 
    1162644330759077909, 
    1162644350631686224, 
    1162644365613748275,
    1162644378070827028, 
    1162644391366766644
  ]